{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести сравнение RNN, LSTM, GRU на датасете отзывов (из предыдущих занятий/материалов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import emoji\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation, ascii_letters\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 2000\n",
    "MAX_LEN = 20\n",
    "EMB_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer(lang='ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(get_stop_words('ru'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation).union((' ', '«', '»', '—', '–', '“', '”', '…'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyrillic_letters = set([chr(i) for i in range(ord('а'), ord('я') + 1)] +\n",
    "                       [chr(i) for i in range(ord('А'), ord('Я') + 1)] +\n",
    "                       ['ё', 'Ё'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../data/summer_reviews.xls')\n",
    "data.columns = ['rating', 'content', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = (data.rating > 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if (set(token).intersection(cyrillic_letters)\n",
    "            or set(token).intersection(set(ascii_letters))\n",
    "            or token in emoji.UNICODE_EMOJI):\n",
    "            result.append(token)\n",
    "    tokens = [token.lower() for token in result if token.lower() not in stop_words]\n",
    "    tokens = [token for token in tokens if token in emoji.UNICODE_EMOJI or len(token) >  1]\n",
    "    tokens = [morph.parse(token)[0].normal_form for token in tokens]\n",
    "    return tokens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed'] = data.content.apply(lambda x: \" \".join(preprocess(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data['processed'], data['target'], test_size=0.1,\n",
    "                                                    random_state=0, stratify=data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=3000, oov_token='UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(tokenizer.texts_to_sequences(X_train),\n",
    "                        maxlen=MAX_LEN,\n",
    "                        padding='post',\n",
    "                        truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pad_sequences(tokenizer.texts_to_sequences(X_val),\n",
    "                        maxlen=MAX_LEN,\n",
    "                        padding='post',\n",
    "                        truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(vocab),\n",
    "                                       output_dim=EMB_SIZE,\n",
    "                                       activity_regularizer=regularizers.l2(1e-6))(inputs)\n",
    "rnn = tf.keras.layers.SimpleRNN(128, recurrent_dropout=0.2, activation='relu')(embeddings)\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(rnn)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18593 samples, validate on 2066 samples\n",
      "Epoch 1/10\n",
      "18593/18593 [==============================] - 3s 170us/sample - loss: 0.4631 - accuracy: 0.8076 - val_loss: 0.3634 - val_accuracy: 0.8621\n",
      "Epoch 2/10\n",
      "18593/18593 [==============================] - 2s 120us/sample - loss: 0.2929 - accuracy: 0.8789 - val_loss: 0.3645 - val_accuracy: 0.9032\n",
      "Epoch 3/10\n",
      "18593/18593 [==============================] - 2s 116us/sample - loss: 0.2494 - accuracy: 0.9010 - val_loss: 0.3016 - val_accuracy: 0.8925\n",
      "Epoch 4/10\n",
      "18593/18593 [==============================] - 2s 120us/sample - loss: 0.2881 - accuracy: 0.8412 - val_loss: 0.3748 - val_accuracy: 0.8170\n",
      "Epoch 5/10\n",
      "18593/18593 [==============================] - 2s 118us/sample - loss: 0.2553 - accuracy: 0.8931 - val_loss: 0.3008 - val_accuracy: 0.8824\n",
      "Epoch 6/10\n",
      "18593/18593 [==============================] - 2s 112us/sample - loss: 0.2231 - accuracy: 0.8996 - val_loss: 0.2924 - val_accuracy: 0.8911\n",
      "Epoch 7/10\n",
      "18593/18593 [==============================] - 2s 117us/sample - loss: 0.2162 - accuracy: 0.9031 - val_loss: 0.2924 - val_accuracy: 0.8756\n",
      "Epoch 8/10\n",
      "18593/18593 [==============================] - 2s 115us/sample - loss: 0.2328 - accuracy: 0.8811 - val_loss: 0.3280 - val_accuracy: 0.9008\n",
      "Epoch 9/10\n",
      "18593/18593 [==============================] - 2s 117us/sample - loss: 0.2247 - accuracy: 0.8993 - val_loss: 0.2925 - val_accuracy: 0.8601\n",
      "Epoch 10/10\n",
      "18593/18593 [==============================] - 2s 116us/sample - loss: 0.2187 - accuracy: 0.9026 - val_loss: 0.3378 - val_accuracy: 0.9095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f56da6e3e90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=256,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(vocab),\n",
    "                                       output_dim=EMB_SIZE,\n",
    "                                       activity_regularizer=regularizers.l2(1e-6))(inputs)\n",
    "lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(embeddings)\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(lstm)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18593 samples, validate on 2066 samples\n",
      "Epoch 1/10\n",
      "18593/18593 [==============================] - 5s 287us/sample - loss: 0.3606 - accuracy: 0.8462 - val_loss: 0.2057 - val_accuracy: 0.9066\n",
      "Epoch 2/10\n",
      "18593/18593 [==============================] - 3s 179us/sample - loss: 0.1995 - accuracy: 0.9192 - val_loss: 0.1848 - val_accuracy: 0.9109\n",
      "Epoch 3/10\n",
      "18593/18593 [==============================] - 3s 182us/sample - loss: 0.1744 - accuracy: 0.9312 - val_loss: 0.1884 - val_accuracy: 0.9163\n",
      "Epoch 4/10\n",
      "18593/18593 [==============================] - 4s 189us/sample - loss: 0.1602 - accuracy: 0.9380 - val_loss: 0.1990 - val_accuracy: 0.9100\n",
      "Epoch 5/10\n",
      "18593/18593 [==============================] - 4s 197us/sample - loss: 0.1461 - accuracy: 0.9443 - val_loss: 0.1994 - val_accuracy: 0.9134\n",
      "Epoch 6/10\n",
      "18593/18593 [==============================] - 3s 179us/sample - loss: 0.1316 - accuracy: 0.9493 - val_loss: 0.2213 - val_accuracy: 0.9085\n",
      "Epoch 7/10\n",
      "18593/18593 [==============================] - 3s 179us/sample - loss: 0.1204 - accuracy: 0.9547 - val_loss: 0.2413 - val_accuracy: 0.9042\n",
      "Epoch 8/10\n",
      "18593/18593 [==============================] - 3s 183us/sample - loss: 0.1064 - accuracy: 0.9601 - val_loss: 0.2845 - val_accuracy: 0.9017\n",
      "Epoch 9/10\n",
      "18593/18593 [==============================] - 3s 179us/sample - loss: 0.0978 - accuracy: 0.9640 - val_loss: 0.2924 - val_accuracy: 0.8969\n",
      "Epoch 10/10\n",
      "18593/18593 [==============================] - 3s 178us/sample - loss: 0.0914 - accuracy: 0.9661 - val_loss: 0.3317 - val_accuracy: 0.9046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f569c6a9f10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=256,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(vocab),\n",
    "                                       output_dim=EMB_SIZE,\n",
    "                                       activity_regularizer=regularizers.l2(1e-6))(inputs)\n",
    "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(embeddings)\n",
    "dense = tf.keras.layers.Dense(64, activation='relu')(gru)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18593 samples, validate on 2066 samples\n",
      "Epoch 1/10\n",
      "18593/18593 [==============================] - 5s 258us/sample - loss: 0.3524 - accuracy: 0.8478 - val_loss: 0.2031 - val_accuracy: 0.9066\n",
      "Epoch 2/10\n",
      "18593/18593 [==============================] - 3s 159us/sample - loss: 0.1983 - accuracy: 0.9177 - val_loss: 0.1863 - val_accuracy: 0.9129\n",
      "Epoch 3/10\n",
      "18593/18593 [==============================] - 3s 160us/sample - loss: 0.1740 - accuracy: 0.9316 - val_loss: 0.1876 - val_accuracy: 0.9124\n",
      "Epoch 4/10\n",
      "18593/18593 [==============================] - 3s 160us/sample - loss: 0.1606 - accuracy: 0.9377 - val_loss: 0.1948 - val_accuracy: 0.9134\n",
      "Epoch 5/10\n",
      "18593/18593 [==============================] - 3s 156us/sample - loss: 0.1504 - accuracy: 0.9429 - val_loss: 0.2061 - val_accuracy: 0.9095\n",
      "Epoch 6/10\n",
      "18593/18593 [==============================] - 3s 162us/sample - loss: 0.1396 - accuracy: 0.9483 - val_loss: 0.2067 - val_accuracy: 0.9105\n",
      "Epoch 7/10\n",
      "18593/18593 [==============================] - 3s 159us/sample - loss: 0.1308 - accuracy: 0.9525 - val_loss: 0.2221 - val_accuracy: 0.9056\n",
      "Epoch 8/10\n",
      "18593/18593 [==============================] - 3s 160us/sample - loss: 0.1199 - accuracy: 0.9563 - val_loss: 0.2362 - val_accuracy: 0.9076\n",
      "Epoch 9/10\n",
      "18593/18593 [==============================] - 3s 155us/sample - loss: 0.1078 - accuracy: 0.9620 - val_loss: 0.2826 - val_accuracy: 0.9066\n",
      "Epoch 10/10\n",
      "18593/18593 [==============================] - 3s 157us/sample - loss: 0.0976 - accuracy: 0.9655 - val_loss: 0.2845 - val_accuracy: 0.9061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5665bb99d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val),\n",
    "          batch_size=256,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, на валидации у всех моделей результат схожий. Если смотреть на лучшую эпоху, то небольшое преимущество у LSTM с результатом `0.9163`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
